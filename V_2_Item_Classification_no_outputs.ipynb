{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srkP_GjkzRMZ"
      },
      "source": [
        "# Document Classification and Translation Notebook\n",
        "\n",
        "This notebook enables classifying and translating document descriptions stored in an archive based on the RIC-O classification system and Netzer & Schuster's suggested vocabulary of document types. It leverages OpenAI's GPT-4 model to perform tasks such as translation, classification, and metadata extraction.\n",
        "\n",
        "## Features\n",
        "\n",
        "- **Interactive UI:** Select operations, add new classifications, and control processing modes.\n",
        "- **Batch Processing with Checkpointing:** Processes data in batches and saves progress incrementally to prevent data loss due to runtime disconnections.\n",
        "- **Detailed Feedback:** Provides summaries post-processing, including success rates and error logs.\n",
        "- **Robust Data Handling:** Ensures consistent and accurate categorization of data.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Ensure you have the necessary API keys for OpenAI and Google Books. These should be securely stored and retrieved within the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rA_CM_PmzRMb"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install necessary libraries\n",
        "%%capture\n",
        "!pip install pandas openai==0.28 requests google-auth google-auth-oauthlib google-auth-httplib2 pydantic tqdm ipywidgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8Bbw7uezRMc"
      },
      "source": [
        "## Import Libraries\n",
        "Import all necessary libraries for data processing, API interactions, and UI components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zp-v6SnlzRMc"
      },
      "outputs": [],
      "source": [
        "# Step 2: Import necessary libraries\n",
        "import pandas as pd\n",
        "from google.colab import drive, userdata\n",
        "import openai\n",
        "import requests\n",
        "import json\n",
        "from collections import defaultdict\n",
        "from pydantic import BaseModel, ValidationError\n",
        "from tqdm import tqdm  # Progress bar\n",
        "import time\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import logging\n",
        "import shutil\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rROUrTtnzRMc"
      },
      "source": [
        "## Mount Google Drive\n",
        "Mount your Google Drive to access input and output files directly from the Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pYK-3_zzRMc"
      },
      "outputs": [],
      "source": [
        "# Step 3: Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDbdvYUZzRMd"
      },
      "source": [
        "## Retrieve API Keys Securely\n",
        "Fetch API keys for OpenAI from Colab's secret management to ensure security."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twyBeeOlzRMd"
      },
      "outputs": [],
      "source": [
        "# Step 4: Retrieve API keys securely from Colab's secret management\n",
        "openai_api_key = userdata.get('openai_api_key')\n",
        "\n",
        "# Initialize OpenAI client with API key\n",
        "openai.api_key = openai_api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvfP1UIvzRMd"
      },
      "source": [
        "## Define Pydantic Model for Response Validation\n",
        "This model ensures that the JSON response from the OpenAI API adheres to the expected structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCOjFAI8zRMd"
      },
      "outputs": [],
      "source": [
        "class TranslationClassificationModel(BaseModel):\n",
        "    german_translation: str = \"\"\n",
        "    english_translation: str = \"\"\n",
        "    item_class: str = \"\"\n",
        "    document_type: str = \"\"\n",
        "    format: str = \"\"\n",
        "    language: str = \"\"\n",
        "    creation_place: str = \"\"\n",
        "    creation_date: str = \"\"\n",
        "    publication_date: str = \"\"\n",
        "    number_of_pages: str = \"\"\n",
        "    documentary_form_type: str = \"\"\n",
        "    production_technique_type: str = \"\"\n",
        "    main_subject: str = \"\"\n",
        "    record_state: str = \"\"\n",
        "    title: str = \"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjVxiNRtzRMe"
      },
      "source": [
        "## Define Classification Lists\n",
        "These lists define the possible classes, document types, formats, languages, production techniques, and record states used for classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTsigsvhzRMe"
      },
      "outputs": [],
      "source": [
        "# Step 6: Define possible classes, document types, formats, languages, and record states\n",
        "classes = [\n",
        "    \"Certificate\", \"Communication Document\", \"Creative Fiction\", \"Creative Nonfiction\", \"EgoDocument\", \"Ephemera\", \"Image\",\n",
        "    \"Legal Document\", \"Report\", \"Medical Document\", \"Financial_Document\", \"Organization Papertrail\"\n",
        "]\n",
        "document_types = [\n",
        "    \"מכתב|Letter\",\n",
        "    \"מעטפה|Envelope\",\n",
        "    \"מסמך מתורגם|Translated Document\",\n",
        "    \"רשימה|List\",\n",
        "    \"קבלה|Receipt\",\n",
        "    \"שיר|Poem\",\n",
        "    \"כרטיס ברכה|Greeting Card\",\n",
        "    \"פתק|Note\",\n",
        "    \"גלויה|Postcard\",\n",
        "    \"כרטיס ביקור|Business Card\",\n",
        "    \"תצלום|Photograph\",\n",
        "    \"פנקס|Notepad\",\n",
        "    \"חוברת|Booklet\",\n",
        "    \"תעודת רישום|Registry Certificate\",\n",
        "    \"הזמנה|Invitation\",\n",
        "    \"מברק|Telegram\",\n",
        "    \"הרצאה|Lecture\",\n",
        "    \"נאום|Speech\",\n",
        "    \"חומר לימודי|School Material\",\n",
        "    \"תעודה|Certificate\",\n",
        "    \"תעודה מנהלית|Administrative Certificate\",\n",
        "    \"עדות|Testimony\",\n",
        "    \"דוח|Report\",\n",
        "    \"תעודת לימודים|Academic Certificate\",\n",
        "    \"קורות חיים|Biography\",\n",
        "    \"מאמר מדעי|Academic Paper\",\n",
        "    \"תוכניית כנס|Conferences Program\",\n",
        "    \"מאמר|Article\",\n",
        "    \"קריקטורה|Caricature\",\n",
        "    \"ספר|Book\",\n",
        "    \"עיתון|Newspaper\",\n",
        "    \"גזיר עיתון|News Clipping\",\n",
        "    \"טיוטה|Draft\",\n",
        "    \"ייפוי כוח|Power of Attorney\",\n",
        "    \"תעודת חבר|Membership Certificate\",\n",
        "    \"כתובה|Ketubah\",\n",
        "    \"הסכם|Agreement\",\n",
        "    \"טופס|Form\",\n",
        "    \"ניירות מכתבים|Stationery\",\n",
        "    \"ברושור|Brochure\",\n",
        "    \"מזכרת|Souvenir\",\n",
        "    \"ציור|Painting\",\n",
        "    \"לא מזוהה|Unrecognized\",\n",
        "    \"טבלה|Table\",\n",
        "    \"כתב עת|Serial\",\n",
        "    \"אינפוגרפיקה|Infographics\",\n",
        "    \"כרטיס|Ticket|Card\",\n",
        "    \"בול|Stamp\",\n",
        "    \"אלמנט גרפי|Graphic Element\",\n",
        "    \"לוגו|Logo\",\n",
        "    \"מפה|Map\",\n",
        "    \"תג|Tag\",\n",
        "    \"תלוש|Voucher\",\n",
        "    \"תכניה|Playbill\",\n",
        "    \"קטלוג|Catalog\",\n",
        "    \"מדריך|Manual\",\n",
        "    \"סימניה|Bookmark\",\n",
        "    \"קומנטר|Commentary\",\n",
        "    \"מרשם רפואי|Medical Prescription\",\n",
        "    \"מתכון|Recipe\",\n",
        "    \"סקיצה|Sketch\",\n",
        "    \"משחק|Game\",\n",
        "    \"בקשה|Application\",\n",
        "    \"מודעת אבל|Death Notice\",\n",
        "    \"דף אינטרנט|Web Page\",\n",
        "    \"המחאה|Check\",\n",
        "    \"חוזה|Contract\",\n",
        "    \"הקדשה|Dedication\",\n",
        "    \"דוא׳ל|Email\",  # Corrected entry using geresh\n",
        "    \"צוואה|Will\",\n",
        "    \"חפץ|Object\",\n",
        "    \"יומן|Diary\",\n",
        "    \"לוח שנה|Calendar\",\n",
        "    \"סיפור|Fiction\",\n",
        "    \"תווים|Scores\",\n",
        "    \"תוכן דתי|Religious Material\",\n",
        "    \"רשימות|Personal Notes\",\n",
        "    \"סיכום פגישה|Minutes\",\n",
        "    \"קולאז'|Collage\",\n",
        "    \"חשבונית|Invoice\",\n",
        "    \"מסמך מורכב|Composite Document\",\n",
        "    \"הסכם|Agreement\",\n",
        "    \"שומר מקום|Place holder\",\n",
        "    \"שרבוט|Doodles\",\n",
        "    \"אוגד|Binder\",\n",
        "    \"תכנית אדריכלית|Floor Plan\",\n",
        "    \"צרור|Bundle\",\n",
        "    \"ספר זכרונות|Memory Book\"\n",
        "]\n",
        "\n",
        "formats = [\n",
        "    \"Handwritten|כתב-יד\", \"Typewritten|הדפסה\", \"Print|דפוס\", \"Visual Element|אלמנט ויזואלי\", \"Unknown|לא ידוע\"\n",
        "]\n",
        "\n",
        "languages = [\n",
        "    \"Hebrew|עברית\", \"English|אנגלית\", \"German|גרמנית\", \"Other|אחר\", \"Unspecified|לא צוין\", \"Irrelevant|לא רלוונטי\"\n",
        "]\n",
        "\n",
        "production_technique_types = [\n",
        "    \"print\", \"handwriting\", \"drawing\", \"typewriting\", \"photography\", \"born-digital\", \"other\"\n",
        "]\n",
        "\n",
        "record_states = [\n",
        "    \"draft\", \"original\", \"copy\", \"other\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgLUSKOUzy5l"
      },
      "outputs": [],
      "source": [
        "\n",
        "## Step 7: Load the Excel File and Extract Column Names for Dropdowns\n",
        "\n",
        "# Define file paths (ensure these paths are correct)\n",
        "input_file_path = '/content/drive/MyDrive/JeckeItems/parsed-items-cleaned.xlsx'  # Update with your file path\n",
        "\n",
        "try:\n",
        "    df = pd.read_excel(input_file_path)\n",
        "    logging.info(f\"Loaded input file successfully with columns: {df.columns.tolist()}\")\n",
        "except FileNotFoundError:\n",
        "    logging.error(f\"Input file not found at path: {input_file_path}\")\n",
        "    df = pd.DataFrame()  # Empty DataFrame to prevent errors\n",
        "\n",
        "# Extract column names for dropdowns\n",
        "column_names = df.columns.tolist()\n",
        "\n",
        "\n",
        "## Step 8: Create Dropdowns for Selecting 'item_id' and 'item_description' Columns\n",
        "\n",
        "# Dropdown for selecting 'item_id' column\n",
        "item_id_dropdown = widgets.Dropdown(\n",
        "    options=column_names,\n",
        "    description='Item ID Column:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Dropdown for selecting 'item_description' column\n",
        "item_description_dropdown = widgets.Dropdown(\n",
        "    options=column_names,\n",
        "    description='Item Description Column:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Display the dropdowns\n",
        "display(widgets.HTML(\"<h2>Select Column Mappings:</h2>\"))\n",
        "display(item_id_dropdown)\n",
        "display(item_description_dropdown)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEjJ6-IlzRMe"
      },
      "source": [
        "## Prompt Building Function\n",
        "Constructs a detailed prompt based on selected operations to send to the OpenAI API. It dynamically includes tasks such as translation, classification, and metadata extraction based on user selections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRhkSJSuzRMe"
      },
      "outputs": [],
      "source": [
        "def build_prompt(description, operations, classes, document_types, formats, languages, production_technique_types, record_states):\n",
        "    prompt = \"Please perform the following tasks for the given Hebrew description of the item:\\n\\n\"\n",
        "\n",
        "    keys = []\n",
        "    task_number = 1  # Keep track of task numbers in the prompt\n",
        "    if operations['translate_german']:\n",
        "        prompt += f\"{task_number}. **Translate** the Hebrew description to **German**.\\n\"\n",
        "        keys.append(\"german_translation\")\n",
        "        task_number += 1\n",
        "    if operations['translate_english']:\n",
        "        prompt += f\"{task_number}. **Translate** the Hebrew description to **English**.\\n\"\n",
        "        keys.append(\"english_translation\")\n",
        "        task_number += 1\n",
        "    if operations['format']:\n",
        "        prompt += f\"{task_number}. **Determine the format** of the document. Choose from: {', '.join(formats)}.\\n\"\n",
        "        prompt += \"Note: When the description mentions 'הדפסה' in the context of letters or documents, it usually refers to 'Typewritten', not 'Print'. Do not assume 'Print' just because letters are involved. If unsure, choose 'Unknown' or 'Handwritten'.\\n\"\n",
        "        keys.append(\"format\")\n",
        "        task_number += 1\n",
        "    if operations['language']:\n",
        "        prompt += f\"{task_number}. **Identify the language(s)** of the document itself. Choose from: {', '.join(languages)}. If multiple languages apply, separate them with a pipe `|`. If the language is not specified or not applicable (e.g., for visual elements with no text), respond with 'Unspecified' or 'Irrelevant' as appropriate.\\n\"\n",
        "        keys.append(\"language\")\n",
        "        task_number += 1\n",
        "    if operations['creation_date']:\n",
        "        prompt += f\"{task_number}. **Determine the creation date** of the document. Provide the most precise date available, in one of the following formats: YYYY-MM-DD, YYYY-MM, or YYYY. Do not fill in missing parts with default values. If the date is not present or cannot be determined, respond with an empty string \\\"\\\".\\n\"\n",
        "        keys.append(\"creation_date\")\n",
        "        task_number += 1\n",
        "    if operations['publication_date']:\n",
        "        prompt += f\"{task_number}. **Determine the publication date** of the document. Provide the most precise date available, in one of the following formats: YYYY-MM-DD, YYYY-MM, or YYYY. Do not fill in missing parts with default values. If the date is not present or cannot be determined, respond with an empty string \\\"\\\".\\n\"\n",
        "        keys.append(\"publication_date\")\n",
        "        task_number += 1\n",
        "    if operations['number_of_pages']:\n",
        "        prompt += f\"{task_number}. **Determine the number of pages** the document has, if mentioned. If not mentioned, respond with an empty string \\\"\\\".\\n\"\n",
        "        keys.append(\"number_of_pages\")\n",
        "        task_number += 1\n",
        "    if operations['documentary_form_type']:\n",
        "        prompt += f\"{task_number}. **Documentary form type:** Indicate 'yes' if the document has a documentary form, otherwise leave it as an empty string \\\"\\\".\\n\"\n",
        "        keys.append(\"documentary_form_type\")\n",
        "        task_number += 1\n",
        "    if operations['production_technique_type']:\n",
        "        prompt += f\"{task_number}. **Specify the production technique type** of the document. Choose from: {', '.join(production_technique_types)}. If not applicable, leave it as an empty string \\\"\\\".\\n\"\n",
        "        keys.append(\"production_technique_type\")\n",
        "        task_number += 1\n",
        "    if operations['main_subject']:\n",
        "        prompt += f\"{task_number}. **Identify the main subject** of the document, if it can be deduced. Only if the main subject is a name of an indivdual or institution. If not, respond with an empty string \\\"\\\".\\n\"\n",
        "        keys.append(\"main_subject\")\n",
        "        task_number += 1\n",
        "    if operations['record_state']:\n",
        "        prompt += f\"{task_number}. **Record state:** Indicate the state of the document. Choose from: {', '.join(record_states)}.\\n\"\n",
        "        prompt += \"Note: For identifying a 'copy', look for Hebrew terms like 'צילום מכתב', 'תצלום מכתב', 'העתק', 'עותק'.\\n\"\n",
        "        keys.append(\"record_state\")\n",
        "        task_number += 1\n",
        "    if operations['title']:\n",
        "        prompt += f\"{task_number}. **Provide a title** for the archival item, containing only essential information based on the description.\\n\"\n",
        "        keys.append(\"title\")\n",
        "        task_number += 1\n",
        "    if operations['item_class']:\n",
        "        prompt += f\"{task_number}. **Suggest the most fitting class** for the item from this list: {', '.join(classes)}.\\n\"\n",
        "        keys.append(\"item_class\")\n",
        "        task_number += 1\n",
        "    if operations['document_type']:\n",
        "        prompt += f\"{task_number}. **Suggest the most fitting document type(s)** for the item from this list: {', '.join(document_types)}. If multiple types apply, separate them with a pipe `|`.\\n\"\n",
        "        keys.append(\"document_type\")\n",
        "        task_number += 1\n",
        "\n",
        "    # Append the actual description\n",
        "    prompt += f\"\\n**Description:**\\n{description}\\n\\n\"\n",
        "\n",
        "    prompt += \"\\n**Important:** Return the result as a structured JSON object with the following keys:\\n\"\n",
        "    for key in keys:\n",
        "        prompt += f\"- \\\"{key}\\\"\\n\"\n",
        "\n",
        "    prompt += \"\\n**Note:** All attributes pertain to the item described, not to the description itself.\\n\\n\"\n",
        "    prompt += \"Example Output:\\n\"\n",
        "    example = {key: \"Example Value\" for key in keys}\n",
        "    prompt += f\"{json.dumps(example, indent=4, ensure_ascii=False)}\\n\"\n",
        "\n",
        "    # **Important Addition:** Instruct the model not to include code fences\n",
        "    prompt += \"\\n**Important:** Do not include any markdown, code fences, or additional text. Return only the JSON object.\"\n",
        "    prompt += \"\\n**Ensure that all keys are included in the JSON output, even if their values are empty strings.**\\n\"\n",
        "\n",
        "    return prompt, keys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVGowdwRzRMf"
      },
      "source": [
        "## OpenAI API Interaction Functions\n",
        "These functions handle communication with the OpenAI API, including error handling and ensuring robust data parsing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tCb2JoFzRMf"
      },
      "outputs": [],
      "source": [
        "def extract_and_translate(description, operations, classes, document_types, formats, languages, production_technique_types, record_states):\n",
        "    prompt, keys = build_prompt(description, operations, classes, document_types, formats, languages, production_technique_types, record_states)\n",
        "\n",
        "    # Optionally, print the prompt for debugging\n",
        "    # print(\"Prompt being sent to OpenAI API:\\n\", prompt)\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o\",  # Corrected model name\n",
        "        messages=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt\n",
        "        }],\n",
        "        temperature=0.2,  # Lower temperature for more deterministic output\n",
        "        max_tokens=1500  # Increased max tokens to accommodate more fields\n",
        "    )\n",
        "\n",
        "    # Extract the assistant's reply\n",
        "    assistant_reply = response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "    return assistant_reply, keys\n",
        "\n",
        "def extract_and_translate_skip_on_failure(description, operations, classes, document_types, formats, languages, production_technique_types, record_states):\n",
        "    try:\n",
        "        return extract_and_translate(description, operations, classes, document_types, formats, languages, production_technique_types, record_states)\n",
        "    except openai.error.OpenAIError as e:\n",
        "        logging.error(f\"OpenAI API error for description: {description[:30]}... Error: {e}. Skipping...\")\n",
        "        return None, []\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Unexpected error for description: {description[:30]}... Error: {e}. Skipping...\")\n",
        "        return None, []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utZtt4xuzRMf"
      },
      "source": [
        "## JSON Parsing Function\n",
        "Safely parses the JSON response from the OpenAI API, ensuring all expected keys are present and handling any malformed JSON by returning default empty values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owusGODUzRMf"
      },
      "outputs": [],
      "source": [
        "def safe_eval(x, keys):\n",
        "    if x is None:\n",
        "        return {key: \"\" for key in keys}\n",
        "    try:\n",
        "        # Remove code fences if present\n",
        "        if x.startswith(\"```\"):\n",
        "            x = \"\\n\".join(x.split(\"\\n\")[1:-1])\n",
        "        result = json.loads(x)\n",
        "        # Validate against Pydantic model for robustness\n",
        "        validated = TranslationClassificationModel(**result)\n",
        "        # Convert validated data back to dict\n",
        "        return validated.dict()\n",
        "    except (json.JSONDecodeError, TypeError, ValidationError) as e:\n",
        "        logging.error(f\"JSON decoding/validation error: {e}\")\n",
        "        logging.error(f\"Raw response: {x[:30]}...\")  # Helps in debugging\n",
        "        return {key: \"\" for key in keys}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5W5knvHzRMf"
      },
      "source": [
        "## Functions to Add New Classes and Document Types\n",
        "Allow users to dynamically add new classes and document types through the UI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uwRNNcPzRMf"
      },
      "outputs": [],
      "source": [
        "def add_new_class(new_class):\n",
        "    new_class = new_class.strip()\n",
        "    if new_class and new_class not in classes:\n",
        "        classes.append(new_class)\n",
        "        return f\"Added new class: {new_class}\"\n",
        "    elif new_class in classes:\n",
        "        return \"Class already exists.\"\n",
        "    else:\n",
        "        return \"No class entered.\"\n",
        "\n",
        "def add_new_document_type(new_doc_type):\n",
        "    new_doc_type = new_doc_type.strip()\n",
        "    if new_doc_type and new_doc_type not in document_types:\n",
        "        document_types.append(new_doc_type)\n",
        "        return f\"Added new document type: {new_doc_type}\"\n",
        "    elif new_doc_type in document_types:\n",
        "        return \"Document type already exists.\"\n",
        "    else:\n",
        "        return \"No document type entered.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCA_q0xAzRMf"
      },
      "source": [
        "## User Interface with `ipywidgets`\n",
        "Create interactive widgets for selecting operations, adding new classifications, and controlling processing modes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejH8hvg1zRMf"
      },
      "outputs": [],
      "source": [
        "## Updated User Interface with Column Selection Dropdowns\n",
        "\n",
        "# Define checkboxes for primary operations\n",
        "translate_german_checkbox = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Translate to German',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "translate_english_checkbox = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Translate to English',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "item_class_checkbox = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Classify Item',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "document_type_checkbox = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Classify Document Type',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Define checkboxes for additional classifications\n",
        "format_checkbox = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Determine Format',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "language_checkbox_widget = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Identify Language',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "creation_place_checkbox = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Creation Place',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "creation_date_checkbox = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Creation Date',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "publication_date_checkbox = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Publication Date',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "number_of_pages_checkbox = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Number of Pages',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "documentary_form_type_checkbox = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Documentary Form Type',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "production_technique_type_checkbox = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Production Technique Type',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "main_subject_checkbox = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Main Subject',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "record_state_checkbox = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Record State',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "title_checkbox = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Title',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Define a checkbox for Test Mode\n",
        "test_mode_checkbox = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Test Mode (Process 10 Rows)',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Text inputs for adding new classes\n",
        "new_class_input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Enter new class',\n",
        "    description='New Class:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "add_class_button = widgets.Button(\n",
        "    description='Add Class',\n",
        "    disabled=False,\n",
        "    button_style='',\n",
        "    tooltip='Click to add new class',\n",
        "    icon='plus'\n",
        ")\n",
        "\n",
        "# Text inputs for adding new document types\n",
        "new_document_type_input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Enter new document type',\n",
        "    description='New Document Type:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "add_document_type_button = widgets.Button(\n",
        "    description='Add Document Type',\n",
        "    disabled=False,\n",
        "    button_style='',\n",
        "    tooltip='Click to add new document type',\n",
        "    icon='plus'\n",
        ")\n",
        "\n",
        "# Output areas for feedback\n",
        "class_output = widgets.Output()\n",
        "document_type_output = widgets.Output()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb3oUOpAzRMg"
      },
      "source": [
        "## Button Click Handlers\n",
        "Define functions to handle button clicks for adding new classes and document types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bsi5NL-_zRMg"
      },
      "outputs": [],
      "source": [
        "# Function to handle adding new class\n",
        "def on_add_class_button_clicked(b):\n",
        "    with class_output:\n",
        "        clear_output()\n",
        "        result = add_new_class(new_class_input.value)\n",
        "        print(result)\n",
        "\n",
        "add_class_button.on_click(on_add_class_button_clicked)\n",
        "\n",
        "# Function to handle adding new document type\n",
        "def on_add_document_type_button_clicked(b):\n",
        "    with document_type_output:\n",
        "        clear_output()\n",
        "        result = add_new_document_type(new_document_type_input.value)\n",
        "        print(result)\n",
        "\n",
        "add_document_type_button.on_click(on_add_document_type_button_clicked)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MlXM3u6zRMg"
      },
      "source": [
        "## Display the Widgets\n",
        "Organize and display all interactive widgets in a visually appealing layout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPJjrIc_zRMg"
      },
      "outputs": [],
      "source": [
        "# Display the dropdowns for column selection\n",
        "column_selection_ui = widgets.VBox([\n",
        "    widgets.HTML(\"<h2>Select Column Mappings:</h2>\"),\n",
        "    widgets.HBox([item_id_dropdown, item_description_dropdown])\n",
        "])\n",
        "\n",
        "# Display the widgets including Test Mode\n",
        "ui = widgets.VBox([\n",
        "    widgets.HTML(\"<h2>Select Operations:</h2>\"),\n",
        "    widgets.HBox([translate_german_checkbox, translate_english_checkbox]),\n",
        "    widgets.HBox([item_class_checkbox, document_type_checkbox]),\n",
        "    widgets.HBox([format_checkbox, language_checkbox_widget]),\n",
        "    widgets.HBox([creation_place_checkbox, creation_date_checkbox]),\n",
        "    widgets.HBox([publication_date_checkbox, number_of_pages_checkbox]),\n",
        "    widgets.HBox([documentary_form_type_checkbox, production_technique_type_checkbox]),\n",
        "    widgets.HBox([main_subject_checkbox, record_state_checkbox]),\n",
        "    widgets.HBox([title_checkbox]),\n",
        "    column_selection_ui,  # Added Column Selection Dropdowns\n",
        "    widgets.HTML(\"<h2>Add New Classifications:</h2>\"),\n",
        "    widgets.HBox([new_class_input, add_class_button]),\n",
        "    class_output,\n",
        "    widgets.HBox([new_document_type_input, add_document_type_button]),\n",
        "    document_type_output,\n",
        "    widgets.HBox([test_mode_checkbox])  # Added Test Mode Checkbox\n",
        "])\n",
        "\n",
        "display(ui)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRAklfsuzRMg"
      },
      "source": [
        "## Data Processing Function\n",
        "Handles loading the data, processing it in batches with checkpointing, interacting with the OpenAI API, and saving the results. It also provides detailed feedback on the processing status."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKS6x0pQzRMg"
      },
      "outputs": [],
      "source": [
        "def process_dataframe(file_path, output_file_path, operations, classes, document_types, formats, languages, production_technique_types, record_states, item_id_column, item_description_column, test_mode=False, batch_size=10, pause_seconds=5):\n",
        "    # Load the Excel file containing the Hebrew descriptions\n",
        "    try:\n",
        "        df = pd.read_excel(file_path)\n",
        "        logging.info(f\"Loaded input file with {df.shape[0]} rows and columns: {df.columns.tolist()}\")\n",
        "    except FileNotFoundError:\n",
        "        logging.error(f\"Input file not found at path: {file_path}\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error loading input file: {e}\")\n",
        "        return\n",
        "\n",
        "    # Ensure the selected columns exist\n",
        "    if item_id_column not in df.columns:\n",
        "        logging.error(f\"Selected Item ID column '{item_id_column}' does not exist in the DataFrame.\")\n",
        "        return\n",
        "    if item_description_column not in df.columns:\n",
        "        logging.error(f\"Selected Item Description column '{item_description_column}' does not exist in the DataFrame.\")\n",
        "        return\n",
        "\n",
        "    # Convert 'item_id' to string and strip whitespace\n",
        "    df[item_id_column] = df[item_id_column].astype(str).str.strip()\n",
        "\n",
        "    # If output file exists, load it\n",
        "    try:\n",
        "        df_existing = pd.read_excel(output_file_path)\n",
        "        df_existing[item_id_column] = df_existing[item_id_column].astype(str).str.strip()\n",
        "        logging.info(f\"Loaded existing output file with {df_existing.shape[0]} rows.\")\n",
        "    except FileNotFoundError:\n",
        "        df_existing = pd.DataFrame()\n",
        "        logging.info(\"No existing output file found. Starting fresh processing.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error loading existing output file: {e}\")\n",
        "        df_existing = pd.DataFrame()\n",
        "\n",
        "    # Merge input and existing output DataFrames\n",
        "    if not df_existing.empty:\n",
        "        df_merged = df.merge(df_existing, on=item_id_column, how='left', suffixes=('', '_processed'))\n",
        "    else:\n",
        "        df_merged = df.copy()\n",
        "\n",
        "    # Identify rows that need processing\n",
        "    # Assume 'title' is a field that should be filled after processing\n",
        "    # Modify 'title' to any key that you expect to be filled after processing\n",
        "    if 'title' in df_existing.columns:\n",
        "        rows_to_process = df_merged[df_merged['title'].isna() | df_merged['title'].eq('')]\n",
        "    else:\n",
        "        rows_to_process = df_merged.copy()\n",
        "\n",
        "    # If Test Mode is enabled, limit to the first 10 rows\n",
        "    if test_mode:\n",
        "        rows_to_process = rows_to_process.head(10)\n",
        "        logging.info(\"Test Mode Enabled: Processing only the first 10 rows.\")\n",
        "\n",
        "    total = rows_to_process.shape[0]\n",
        "    successes = 0\n",
        "    skipped = 0\n",
        "\n",
        "    logging.info(f\"Total items to process: {total}\")\n",
        "\n",
        "    # Build the keys list based on selected operations\n",
        "    keys = []\n",
        "    if operations['translate_german']:\n",
        "        keys.append(\"german_translation\")\n",
        "    if operations['translate_english']:\n",
        "        keys.append(\"english_translation\")\n",
        "    if operations['format']:\n",
        "        keys.append(\"format\")\n",
        "    if operations['language']:\n",
        "        keys.append(\"language\")\n",
        "    if operations['creation_place']:\n",
        "        keys.append(\"creation_place\")\n",
        "    if operations['creation_date']:\n",
        "        keys.append(\"creation_date\")\n",
        "    if operations['publication_date']:\n",
        "        keys.append(\"publication_date\")\n",
        "    if operations['number_of_pages']:\n",
        "        keys.append(\"number_of_pages\")\n",
        "    if operations['documentary_form_type']:\n",
        "        keys.append(\"documentary_form_type\")\n",
        "    if operations['production_technique_type']:\n",
        "        keys.append(\"production_technique_type\")\n",
        "    if operations['main_subject']:\n",
        "        keys.append(\"main_subject\")\n",
        "    if operations['record_state']:\n",
        "        keys.append(\"record_state\")\n",
        "    if operations['title']:\n",
        "        keys.append(\"title\")\n",
        "    if operations['item_class']:\n",
        "        keys.append(\"item_class\")\n",
        "    if operations['document_type']:\n",
        "        keys.append(\"document_type\")\n",
        "\n",
        "    # Ensure keys are unique\n",
        "    keys = list(set(keys))\n",
        "\n",
        "    # Define selected_columns based on original columns and keys\n",
        "    original_columns = [item_id_column, item_description_column]\n",
        "    selected_columns = original_columns + keys\n",
        "\n",
        "    # Prepare a list to collect new processed data\n",
        "    parsed_rows = []\n",
        "\n",
        "    # Process in batches to handle large datasets and prevent runtime disconnections\n",
        "    for start in tqdm(range(0, total, batch_size), desc=\"Processing Batches\"):\n",
        "        end = min(start + batch_size, total)\n",
        "        batch = rows_to_process.iloc[start:end]\n",
        "        logging.debug(f\"Processing batch from index {start} to {end}\")\n",
        "\n",
        "        for idx, row in batch.iterrows():\n",
        "            item_id = str(row[item_id_column]).strip()\n",
        "            description = row[item_description_column]\n",
        "\n",
        "            if pd.notnull(description) and str(description).strip() != '':\n",
        "                extracted, _ = extract_and_translate_skip_on_failure(\n",
        "                    description,\n",
        "                    operations,\n",
        "                    classes,\n",
        "                    document_types,\n",
        "                    formats,\n",
        "                    languages,\n",
        "                    production_technique_types,\n",
        "                    record_states\n",
        "                )\n",
        "                if extracted:\n",
        "                    parsed = safe_eval(extracted, keys)\n",
        "                    # Create a new row dictionary including original and new data\n",
        "                    new_row = {item_id_column: item_id, item_description_column: description}\n",
        "                    new_row.update(parsed)\n",
        "                    parsed_rows.append(new_row)  # Accumulate parsed rows\n",
        "                    successes += 1\n",
        "                    logging.debug(f\"Successfully processed item ID {item_id}\")\n",
        "                else:\n",
        "                    skipped += 1\n",
        "                    logging.debug(f\"Skipped item ID {item_id} due to extraction failure.\")\n",
        "            else:\n",
        "                skipped += 1\n",
        "                logging.debug(f\"No valid description for item ID {item_id}. Skipping.\")\n",
        "\n",
        "        # After processing each batch, append the new data to the existing output DataFrame and save\n",
        "        if parsed_rows:\n",
        "            logging.info(f\"Number of parsed rows in current batch: {len(parsed_rows)}\")\n",
        "            df_new = pd.DataFrame(parsed_rows, columns=selected_columns)\n",
        "            if not df_existing.empty:\n",
        "                df_existing = pd.concat([df_existing, df_new], ignore_index=True)\n",
        "            else:\n",
        "                df_existing = df_new.copy()\n",
        "            # Remove duplicates based on 'item_id'\n",
        "            df_existing.drop_duplicates(subset=[item_id_column], keep='last', inplace=True)\n",
        "            try:\n",
        "                df_existing.to_excel(output_file_path, index=False)\n",
        "                logging.info(f\"Batch {start // batch_size + 1} processed and saved to {output_file_path}.\")\n",
        "                # Create a backup\n",
        "                backup_path = output_file_path.replace('.xlsx', '_backup.xlsx')\n",
        "                shutil.copyfile(output_file_path, backup_path)\n",
        "                logging.info(f\"Backup created at {backup_path}\")\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Failed to save output file: {e}\")\n",
        "            parsed_rows = []  # Reset parsed_rows for the next batch\n",
        "        else:\n",
        "            logging.info(\"No new rows parsed in this batch.\")\n",
        "\n",
        "        # Pause between batches to prevent runtime disconnections\n",
        "        time.sleep(pause_seconds)\n",
        "\n",
        "    # Display processing summary\n",
        "    logging.info(f\"\\nProcessing Summary:\")\n",
        "    logging.info(f\"Total Items to Process: {total}\")\n",
        "    logging.info(f\"Successfully Processed: {successes}\")\n",
        "    logging.info(f\"Skipped Entries: {skipped}\")\n",
        "    logging.info(f\"Processed file saved to: {output_file_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJxTfB3zzRMg"
      },
      "source": [
        "## Process Button and Handler\n",
        "Creates a button that, when clicked, initiates the data processing workflow based on the selected operations and configurations. It also handles resumable processing by skipping already processed entries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEBbijKrzRMg"
      },
      "outputs": [],
      "source": [
        "## Updated Process Button and Handler\n",
        "## Creates a button that, when clicked, initiates the data processing workflow based on the selected operations and configurations. It also handles resumable processing by skipping already processed entries.\n",
        "\n",
        "# Create a Button to Trigger the Processing\n",
        "process_button = widgets.Button(\n",
        "    description='Process Data',\n",
        "    disabled=False,\n",
        "    button_style='success',\n",
        "    tooltip='Click to process the data with selected operations',\n",
        "    icon='cogs'\n",
        ")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_process_button_clicked(b):\n",
        "    with output:\n",
        "        clear_output()\n",
        "        # Define the operations based on current UI selections\n",
        "        operations = {\n",
        "            'translate_german': translate_german_checkbox.value,\n",
        "            'translate_english': translate_english_checkbox.value,\n",
        "            'item_class': item_class_checkbox.value,\n",
        "            'document_type': document_type_checkbox.value,\n",
        "            'format': format_checkbox.value,\n",
        "            'language': language_checkbox_widget.value,\n",
        "            'creation_place': creation_place_checkbox.value,\n",
        "            'creation_date': creation_date_checkbox.value,\n",
        "            'publication_date': publication_date_checkbox.value,\n",
        "            'number_of_pages': number_of_pages_checkbox.value,\n",
        "            'documentary_form_type': documentary_form_type_checkbox.value,\n",
        "            'production_technique_type': production_technique_type_checkbox.value,\n",
        "            'main_subject': main_subject_checkbox.value,\n",
        "            'record_state': record_state_checkbox.value,\n",
        "            'title': title_checkbox.value\n",
        "        }\n",
        "\n",
        "        # Update the classes and document_types with any new additions\n",
        "        current_classes = classes.copy()\n",
        "        current_document_types = document_types.copy()\n",
        "\n",
        "        # Define file paths (ensure these paths are correct)\n",
        "        input_file_path = '/content/drive/MyDrive/JeckeItems/parsed-items-cleaned.xlsx'  # Update with your file path\n",
        "        output_file_path = '/content/drive/MyDrive/JeckeItems/Classified_parsed-items-cleaned.xlsx.xlsx'  # Update as needed\n",
        "\n",
        "        # Check if Test Mode is enabled\n",
        "        test_mode = test_mode_checkbox.value\n",
        "\n",
        "        # Retrieve selected columns from dropdowns\n",
        "        item_id_column = item_id_dropdown.value\n",
        "        item_description_column = item_description_dropdown.value\n",
        "\n",
        "        # Validate that the user has selected different columns\n",
        "        if item_id_column == item_description_column:\n",
        "            print(\"Error: 'Item ID Column' and 'Item Description Column' must be different.\")\n",
        "            return\n",
        "\n",
        "        # Display starting message\n",
        "        print(\"Starting data processing...\")\n",
        "        print(f\"Selected 'Item ID Column': {item_id_column}\")\n",
        "        print(f\"Selected 'Item Description Column': {item_description_column}\")\n",
        "\n",
        "        process_dataframe(\n",
        "            file_path=input_file_path,\n",
        "            output_file_path=output_file_path,\n",
        "            operations=operations,\n",
        "            classes=current_classes,\n",
        "            document_types=current_document_types,\n",
        "            formats=formats,\n",
        "            languages=languages,\n",
        "            production_technique_types=production_technique_types,\n",
        "            record_states=record_states,\n",
        "            item_id_column=item_id_column,\n",
        "            item_description_column=item_description_column,\n",
        "            test_mode=test_mode  # Pass the test_mode flag\n",
        "        )\n",
        "\n",
        "process_button.on_click(on_process_button_clicked)\n",
        "\n",
        "# Display the process button and output area\n",
        "display(widgets.HBox([process_button]), output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmE2BcYvzRMh"
      },
      "source": [
        "## Usage Instructions\n",
        "\n",
        "1. **Select Operations:** Check the boxes corresponding to the tasks you want to perform (e.g., translation, classification).\n",
        "\n",
        "2. **Add New Classifications (Optional):** Use the text inputs and buttons to add new classes or document types as needed.\n",
        "\n",
        "3. **Test Mode (Optional):** Enable Test Mode to process only the first 10 rows for testing purposes.\n",
        "\n",
        "4. **Process Data:** Click the **Process Data** button to start processing. The notebook will process data in batches, saving progress after each batch. If a runtime disconnection occurs, simply re-run the **Process Data** cell to resume processing from the last saved point.\n",
        "\n",
        "5. **Review Output:** The processed data will be saved to the specified output file path in your Google Drive. Upon completion, a summary of the processing status will be displayed."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}